{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-12T07:38:54.597776Z","iopub.execute_input":"2022-05-12T07:38:54.598207Z","iopub.status.idle":"2022-05-12T07:38:54.682466Z","shell.execute_reply.started":"2022-05-12T07:38:54.598096Z","shell.execute_reply":"2022-05-12T07:38:54.681454Z"},"trusted":true,"id":"dz_13t_2ptBz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pyspark"],"metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:24:29.141304Z","iopub.execute_input":"2021-06-22T05:24:29.14168Z","iopub.status.idle":"2021-06-22T05:25:08.012775Z","shell.execute_reply.started":"2021-06-22T05:24:29.141648Z","shell.execute_reply":"2021-06-22T05:25:08.011608Z"},"trusted":true,"id":"GFfyn0vpptB2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pyspark\n","from IPython.display import display, clear_output\n","from pyspark.sql import SparkSession, DataFrame\n","from pyspark.sql import functions as f\n","import pandas as pd\n","from pyspark.ml import PipelineModel\n","from pyspark.sql.functions import udf\n","from pyspark.sql.streaming import DataStreamReader\n","import html\n","\n","pd.options.display.max_columns = None\n","pd.options.display.max_rows = 30\n","pd.options.display.max_colwidth = 150\n","\n","\n","\n","# SETTINGS\n","IN_PATH = \"/kaggle/input/twitter-data-for-spark-streaming/\"\n","#IN_PATH = \"./twitterdata\"\n","timestampformat = \"EEE MMM dd HH:mm:ss zzzz yyyy\"\n","\n","spark = SparkSession.builder.appName(\"StructuredStreamingExample\").getOrCreate()\n","spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n","spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")\n","schema = spark.read.json(IN_PATH).limit(10).schema\n","\n","\n","spark_reader = spark.readStream.schema(schema)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:27:20.571835Z","iopub.execute_input":"2021-06-22T05:27:20.572192Z","iopub.status.idle":"2021-06-22T05:27:24.750326Z","shell.execute_reply.started":"2021-06-22T05:27:20.572163Z","shell.execute_reply":"2021-06-22T05:27:24.749194Z"},"trusted":true,"id":"o_UNIbtjptB3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spark.version"],"metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:27:29.166237Z","iopub.execute_input":"2021-06-22T05:27:29.166595Z","iopub.status.idle":"2021-06-22T05:27:29.176015Z","shell.execute_reply.started":"2021-06-22T05:27:29.166566Z","shell.execute_reply":"2021-06-22T05:27:29.17499Z"},"trusted":true,"id":"cADfT1gCptB3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#spark_reader.json(IN_PATH).show(2)\n","#spark_reader.json(IN_PATH).printSchema()"],"metadata":{"trusted":true,"id":"Ie-Ft4ImptB4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = (\n","    spark_reader.json(IN_PATH)\n","    .select(\n","        \"id\",\n","        # extract proper timestamp from created_at column\n","        f.to_timestamp(f.col(\"created_at\"), timestampformat).alias(\"timestamp\"),\n","        # extract user information\n","        f.col(\"user.screen_name\").alias(\"user\"),\n","        \"text\",\n","    )\n","    .coalesce(1)\n",")\n","distinct_user_count = df.select(f.approx_count_distinct(\"user\"), f.current_timestamp())"],"metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:14:08.844177Z","iopub.execute_input":"2021-06-20T02:14:08.844499Z","iopub.status.idle":"2021-06-20T02:14:08.929844Z","shell.execute_reply.started":"2021-06-20T02:14:08.844472Z","shell.execute_reply":"2021-06-20T02:14:08.928791Z"},"trusted":true,"id":"62crdWu7ptB4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if not df.isStreaming:\n","    print(\"Plain old, basic DataFrame\")\n","    # Some actions only work on non-streaming DataFrames, like show and toPandas\n","    distinct_user_count.show()\n","    display(df.limit(5).toPandas())\n","else:\n","    print(\"We are streaming!\")\n","    # Creating a DataSreamWriter and StreamingQuery\n","    # ===\n","    # Calling .writeStream on a DataFrame returns an instance of DataStreamWriter\n","    stream_writer = (\n","        distinct_user_count.writeStream\n","        # DataStream queries need to be named\n","        .queryName(\"distinct_user_count\")\n","        .trigger(\n","            # processingTime=\"5 seconds\",\n","            # Setting 'once' to True will make spark only process the stream 1 time - great for debugging\n","            once=True,\n","        )\n","        .outputMode(\"complete\")\n","        .format(\"memory\")\n","    )\n","    # Calling .start on a DataStreamWriter return an instance of StreamingQuery\n","    query = stream_writer.start()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:14:12.325795Z","iopub.execute_input":"2021-06-20T02:14:12.326147Z","iopub.status.idle":"2021-06-20T02:14:12.379266Z","shell.execute_reply.started":"2021-06-20T02:14:12.326112Z","shell.execute_reply":"2021-06-20T02:14:12.378196Z"},"trusted":true,"id":"lYJkVzlfptB4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# .isStreaming can be used to determine if DataFrame is of Streaming kind or not\n","df.isStreaming"],"metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:58:20.865828Z","iopub.execute_input":"2021-06-20T01:58:20.866171Z","iopub.status.idle":"2021-06-20T01:58:20.87127Z","shell.execute_reply.started":"2021-06-20T01:58:20.866137Z","shell.execute_reply":"2021-06-20T01:58:20.870574Z"},"trusted":true,"id":"bJO_N4I2ptB4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# .isActive shows if the query is actively running or not\n","query.isActive"],"metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:58:39.201287Z","iopub.execute_input":"2021-06-20T01:58:39.20162Z","iopub.status.idle":"2021-06-20T01:58:39.207359Z","shell.execute_reply.started":"2021-06-20T01:58:39.201589Z","shell.execute_reply":"2021-06-20T01:58:39.206443Z"},"trusted":true,"id":"BZ5bR9UJptB5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# .start() transforms a DataStreamWriter to a StreamingQuery and starts the query execution\n","if not query.isActive:\n","    query = stream_writer.start()\n","\n","# Calling .start on an already active StreamingQuery will raise an IllegalArgumentException\n","# -> 'Cannot start query with name {StreamingQuery.name} as a query with that name is already active'"],"metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:58:43.417886Z","iopub.execute_input":"2021-06-20T01:58:43.418498Z","iopub.status.idle":"2021-06-20T01:58:43.483369Z","shell.execute_reply.started":"2021-06-20T01:58:43.418461Z","shell.execute_reply":"2021-06-20T01:58:43.482201Z"},"trusted":true,"id":"TlQOytf5ptB5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# spark.sql can be used to request how the query is performing\n","display(spark.sql(f\"SELECT * from {query.name}\").toPandas())"],"metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:58:47.675707Z","iopub.execute_input":"2021-06-20T01:58:47.676019Z","iopub.status.idle":"2021-06-20T01:58:47.813591Z","shell.execute_reply.started":"2021-06-20T01:58:47.675992Z","shell.execute_reply":"2021-06-20T01:58:47.812622Z"},"trusted":true,"id":"InF9_mUPptB5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# show live results for 2 minutes, refreshed every 1 second\n","from time import sleep\n","for x in range(0, 120):\n","    # spark.sql can be used to request how the query is performing\n","    display(spark.sql(f\"SELECT * from {query.name}\").toPandas())\n","    sleep(1)\n","    clear_output(wait=True)\n","else:\n","    print(\"Live view ended...\")"],"metadata":{"execution":{"iopub.status.busy":"2021-06-20T01:58:52.965756Z","iopub.execute_input":"2021-06-20T01:58:52.966101Z","iopub.status.idle":"2021-06-20T02:00:56.17733Z","shell.execute_reply.started":"2021-06-20T01:58:52.966056Z","shell.execute_reply":"2021-06-20T02:00:56.176333Z"},"trusted":true,"id":"tY0aIUnhptB6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@udf\n","def html_unescape(s: str):\n","    if isinstance(s, str):\n","        return html.unescape(s)\n","    return s\n","\n","\n","def clean_data(df: DataFrame):\n","    url_regex = r\"((https?|ftp|file):\\/{2,3})+([-\\w+&@#/%=~|$?!:,.]*)|(www.)+([-\\w+&@#/%=~|$?!:,.]*)\"\n","    email_regex = r\"[\\w.-]+@[\\w.-]+\\.[a-zA-Z]{1,}\"\n","    user_regex = r\"(@\\w{1,15})\"\n","\n","    return (\n","        df\n","\n","        # Store the original text column in a new column for future reference\n","        .withColumn(\"original_text\", f.col(\"text\"))\n","\n","        # Remove email addresses, URLs, and user mentions\n","        .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), url_regex, \"\"))\n","        .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), email_regex, \"\"))\n","        .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), user_regex, \"\"))\n","        .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), \"#\", \" \"))\n","\n","        # Unescape any HTML\n","        .withColumn(\"text\", html_unescape(f.col(\"text\")))\n","\n","        # Remove all numbers, double/multiple spaces, and leading/trailing whitespaces\n","        .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), \"[^a-zA-Z']\", \" \"))\n","        .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), \" +\", \" \"))\n","        .withColumn(\"text\", f.trim(f.col(\"text\")))\n","\n","        # Ensure we don't end up with empty rows\n","        .filter(f.col(\"text\") != \"\").na.drop(subset=\"text\")\n","    )\n"],"metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:21:39.082891Z","iopub.execute_input":"2021-06-20T02:21:39.083243Z","iopub.status.idle":"2021-06-20T02:21:39.091402Z","shell.execute_reply.started":"2021-06-20T02:21:39.083209Z","shell.execute_reply":"2021-06-20T02:21:39.090216Z"},"trusted":true,"id":"fr73SvuZptB6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["streaming_data_raw = (\n","    spark_reader.json(IN_PATH)\n","    .select(\n","        \"id\",\n","        # extract proper timestamp from created_at column\n","        f.to_timestamp(f.col(\"created_at\"), timestampformat).alias(\"timestamp\"),\n","        # extract user information\n","        f.col(\"user.screen_name\").alias(\"user\"),\n","        \"text\",\n","    )\n","    .coalesce(1)\n",")\n","streaming_data_clean = clean_data(streaming_data_raw)\n","\n","stream_writer = (streaming_data_clean.writeStream.queryName(\"data\").trigger(once=True).outputMode(\"append\").format(\"memory\"))\n","\n","query = stream_writer.start()\n"],"metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:45:22.998766Z","iopub.execute_input":"2021-06-20T02:45:22.999112Z","iopub.status.idle":"2021-06-20T02:45:23.228968Z","shell.execute_reply.started":"2021-06-20T02:45:22.999058Z","shell.execute_reply":"2021-06-20T02:45:23.228252Z"},"trusted":true,"id":"VH61VgfhptB6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["display(spark.sql(f\"SELECT * from {query.name}\").show())"],"metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:45:25.743844Z","iopub.execute_input":"2021-06-20T02:45:25.744193Z","iopub.status.idle":"2021-06-20T02:45:25.818657Z","shell.execute_reply.started":"2021-06-20T02:45:25.744157Z","shell.execute_reply":"2021-06-20T02:45:25.817982Z"},"trusted":true,"id":"XZdLHRudptB7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["distinct_user_count = streaming_data_clean.select(f.approx_count_distinct(\"user\"), f.current_timestamp())\n","\n","stream_writer = (distinct_user_count.writeStream.queryName(\"data\").trigger(once=True).outputMode(\"complete\").format(\"memory\"))\n","\n","query = stream_writer.start()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:47:37.745244Z","iopub.execute_input":"2021-06-20T02:47:37.745593Z","iopub.status.idle":"2021-06-20T02:47:37.804249Z","shell.execute_reply.started":"2021-06-20T02:47:37.745558Z","shell.execute_reply":"2021-06-20T02:47:37.803462Z"},"trusted":true,"id":"fm24XSpUptB7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["display(spark.sql(f\"SELECT * from {query.name}\").show())"],"metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:47:40.248324Z","iopub.execute_input":"2021-06-20T02:47:40.248672Z","iopub.status.idle":"2021-06-20T02:47:40.293216Z","shell.execute_reply.started":"2021-06-20T02:47:40.248643Z","shell.execute_reply":"2021-06-20T02:47:40.292279Z"},"trusted":true,"id":"grcIYUvaptB7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentiment_model = PipelineModel.load(\"/kaggle/input/pyspark-nlp/MODEL\")\n","raw_sentiment = sentiment_model.transform(streaming_data_clean)\n","\n","# Select downstream columns\n","sentiment = raw_sentiment.select(\n","    \"id\", \"timestamp\", \"user\", \"text\", f.col(\"prediction\").alias(\"user_sentiment\")\n",")\n"],"metadata":{"execution":{"iopub.status.busy":"2021-06-22T05:35:31.858615Z","iopub.execute_input":"2021-06-22T05:35:31.858971Z","iopub.status.idle":"2021-06-22T05:35:36.984593Z","shell.execute_reply.started":"2021-06-22T05:35:31.858942Z","shell.execute_reply":"2021-06-22T05:35:36.983351Z"},"trusted":true,"id":"vTytka14ptB7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stream_writer = (sentiment.writeStream.queryName(\"data\").trigger(once=True).outputMode(\"append\").format(\"memory\"))\n","\n","query = stream_writer.start()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:56:48.021006Z","iopub.execute_input":"2021-06-20T02:56:48.021405Z","iopub.status.idle":"2021-06-20T02:56:48.081037Z","shell.execute_reply.started":"2021-06-20T02:56:48.02137Z","shell.execute_reply":"2021-06-20T02:56:48.079679Z"},"trusted":true,"id":"cIW1bVpMptB7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["display(spark.sql(f\"SELECT * from {query.name}\").show())"],"metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:56:50.20881Z","iopub.execute_input":"2021-06-20T02:56:50.209165Z","iopub.status.idle":"2021-06-20T02:56:50.311888Z","shell.execute_reply.started":"2021-06-20T02:56:50.209133Z","shell.execute_reply":"2021-06-20T02:56:50.310286Z"},"trusted":true,"id":"VJ4QG881ptB8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["negative_sentiment_count = (\n","    sentiment.filter(\"user_sentiment == 0.0\")\n","    .select(f.col(\"user_sentiment\").alias(\"negative_sentiment\"))\n","    .agg(f.count(\"negative_sentiment\"))\n",")\n","\n","positive_sentiment_count = (\n","    sentiment.filter(\"user_sentiment == 4.0\")\n","    .select(f.col(\"user_sentiment\").alias(\"positive_sentiment\"))\n","    .agg(f.count(\"positive_sentiment\"))\n",")\n","\n","average_sentiment = sentiment.agg(f.avg(\"user_sentiment\"))"],"metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:57:26.953006Z","iopub.execute_input":"2021-06-20T02:57:26.95341Z","iopub.status.idle":"2021-06-20T02:57:27.018549Z","shell.execute_reply.started":"2021-06-20T02:57:26.953374Z","shell.execute_reply":"2021-06-20T02:57:27.017676Z"},"trusted":true,"id":"y7ZzwiKzptB8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_to_stream = average_sentiment"],"metadata":{"execution":{"iopub.status.busy":"2021-06-19T17:23:01.109204Z","iopub.execute_input":"2021-06-19T17:23:01.109632Z","iopub.status.idle":"2021-06-19T17:23:01.113938Z","shell.execute_reply.started":"2021-06-19T17:23:01.109575Z","shell.execute_reply":"2021-06-19T17:23:01.112413Z"},"trusted":true,"id":"woGBVO2YptB8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_to_stream = negative_sentiment_count"],"metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:51:19.839181Z","iopub.execute_input":"2021-06-20T02:51:19.839533Z","iopub.status.idle":"2021-06-20T02:51:19.844298Z","shell.execute_reply.started":"2021-06-20T02:51:19.839502Z","shell.execute_reply":"2021-06-20T02:51:19.842915Z"},"trusted":true,"id":"goLQQkFoptB8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_to_stream = positive_sentiment_count"],"metadata":{"execution":{"iopub.status.busy":"2021-06-19T17:30:52.856859Z","iopub.execute_input":"2021-06-19T17:30:52.857207Z","iopub.status.idle":"2021-06-19T17:30:52.862028Z","shell.execute_reply.started":"2021-06-19T17:30:52.857177Z","shell.execute_reply":"2021-06-19T17:30:52.861113Z"},"trusted":true,"id":"mXjyXmMTptB8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if isinstance(spark_reader, DataStreamReader):\n","    stream_writer = (\n","        data_to_stream.writeStream.queryName(\"streaming_table\")\n","        .trigger(processingTime=\"20 seconds\")\n","        #.trigger(once=True)\n","        .outputMode(\"complete\")\n","        .format(\"memory\")\n","    )\n","    # Calling .start on a DataStreamWriter return an instance of StreamingQuery\n","    query = stream_writer.start()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:53:12.569757Z","iopub.execute_input":"2021-06-20T02:53:12.57011Z","iopub.status.idle":"2021-06-20T02:53:12.616902Z","shell.execute_reply.started":"2021-06-20T02:53:12.570064Z","shell.execute_reply":"2021-06-20T02:53:12.615763Z"},"trusted":true,"id":"CbTqcbgvptB9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["display(spark.sql(f\"SELECT * from {query.name}\").show())"],"metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:53:23.108138Z","iopub.execute_input":"2021-06-20T02:53:23.108448Z","iopub.status.idle":"2021-06-20T02:53:23.151766Z","shell.execute_reply.started":"2021-06-20T02:53:23.10842Z","shell.execute_reply":"2021-06-20T02:53:23.150603Z"},"trusted":true,"id":"GhaxZ3coptB9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["streaming_data_clean.isStreaming"],"metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:59:24.958042Z","iopub.execute_input":"2021-06-20T02:59:24.958411Z","iopub.status.idle":"2021-06-20T02:59:24.964099Z","shell.execute_reply.started":"2021-06-20T02:59:24.958373Z","shell.execute_reply":"2021-06-20T02:59:24.963228Z"},"trusted":true,"id":"v7NVEsr4ptB9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's see what we are outputting\n","if streaming_data_clean.isStreaming:\n","    from time import sleep\n","    for x in range(0, 200):\n","        try:\n","            if not query.isActive:\n","                break\n","            print(\"Showing live view refreshed every 10 seconds\")\n","            print(f\"Seconds passed: {x*10}\")\n","            result = spark.sql(f\"SELECT * from {query.name}\")\n","            # spark.sql can be used to request how the query is performing\n","            display(result.toPandas())\n","            sleep(10)\n","            clear_output(wait=True)\n","        except KeyboardInterrupt:\n","            break\n","    print(\"Live view ended...\")\n","else:\n","    print(\"Not streaming, showing static output instead\")\n","    result = data_to_stream\n","    display(result.limit(10).toPandas())"],"metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:59:52.396562Z","iopub.execute_input":"2021-06-20T02:59:52.397832Z","iopub.status.idle":"2021-06-20T02:59:52.406566Z","shell.execute_reply.started":"2021-06-20T02:59:52.397773Z","shell.execute_reply":"2021-06-20T02:59:52.405568Z"},"trusted":true,"id":"qwQiXbJ3ptB9"},"execution_count":null,"outputs":[]}]}